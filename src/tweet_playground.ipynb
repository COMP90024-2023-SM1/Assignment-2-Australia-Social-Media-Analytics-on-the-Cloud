{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "@_Cristian_Vlad_ @PenelopeRuzy @sadino22 @130629130629 @Margaret_Krac @Scorpianking50 @CherrylezamaPaz @Verywimp @AnatCastle @StefanSubotic91 @ArHokum @MalikaAkram14 @JohnKish20 @EehHorn @TopogigioRini @maype7 @mmjoymm_StP @santer_karen @appoline85 @lynda3035 @poupouch48 @ElveroW @leeduca @blakiecarmen @TapardeaA @promorama39 @MoishesMom @Pho2oart @Masterc97659979 @Eva82040306 @DianeK23502279 @christelaaldrs @Chandra1Vinod @twistabout @yazidyaks @111ayasuko @kelly_rdc @KarenBarryDavi1 @cookiemutt @47X4GyQMc5Xbi31 @dew_frank @SLARTZONE @crea_bea_5 @dailyreport4me @BrianCapry @TammyJLemley @lausaysmeow @oftadrian @Gatuzs Happy #Purrsday to you as well! üíö\n",
      "@KellyODwyer @bridgetarcher @sallymcmanus ICAC? What is the #LNPCorruptionParty #LNPCrimeFamily afraid of?\n",
      "@ScottMorrisonMP Scott you appear to be campaigning? Have you called an election? If not doesn't this go against our laws? Campaigning on the tax payers dime?  #auspol #ScottyFromMarketing\n",
      "@ScottMorrisonMP @RonniSalt Using your wife to fish for insults to take offence at is a bit much, #ScottyTheCreep ..... will you be getting the girls out again if the response disappoints?\n",
      "#auspol\n"
     ]
    }
   ],
   "source": [
    "with open('../data/twitter-huge.json', 'r') as file:\n",
    "    for index, text in enumerate(file):\n",
    "        if index != 0:\n",
    "            text = json.loads(text[:-2])\n",
    "            if text['value']['tags'] != '':\n",
    "                print(text['doc']['data']['text'])\n",
    "        if index == 100:\n",
    "            break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['auspol', 'ScottyFromMarketing']"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'auspol|ScottyFromMarketing'.split('|')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "52 7900136492\n",
      "7900136492 15800273362\n",
      "15800273362 23700410858\n",
      "23700410858 31600547649\n",
      "31600547649 39500684386\n",
      "39500684386 47400821157\n",
      "47400821157 55300958364\n",
      "55300958364 63201091459\n"
     ]
    }
   ],
   "source": [
    "dataset_size = os.path.getsize('../data/twitter-huge.json')\n",
    "size_per_core = dataset_size / 8\n",
    "\n",
    "\n",
    "with open('../data/twitter-huge.json', 'r', encoding='utf-8') as file:\n",
    "    # Read pass the first line\n",
    "    file.readline()\n",
    "    block_end = file.tell()\n",
    "\n",
    "    while True:\n",
    "        block_start = block_end\n",
    "        file.seek(file.tell() + size_per_core)\n",
    "        # Read the next line to prevent reading partial tweet\n",
    "        file.readline()\n",
    "        block_end = file.tell()\n",
    "\n",
    "        if block_end > dataset_size:\n",
    "            block_end = dataset_size\n",
    "            \n",
    "        print(str(block_start) + \" \" + str(block_end))\n",
    "        if block_end == dataset_size:\n",
    "            break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "}]}}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "with open('../data/twitter-huge.json', 'r', encoding='utf-8') as file:\n",
    "    file.seek(63201091450)\n",
    "    line = file.readline()\n",
    "    print(line)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['line,']"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'line,'.splitlines()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime\n",
    "\n",
    "DATE_FORMAT = \"%Y-%m-%dT%H:%M:%S.%fZ\"\n",
    "\n",
    "def extract_tweet_info(one_tweet):\n",
    "    \"\"\"\n",
    "    Extract necessary information of a tweet and returns in\n",
    "    JSON format\n",
    "\n",
    "    Arguments:\n",
    "    one_tweet --- one tweet JSON object\n",
    "    \"\"\"\n",
    "    # Parse date format into YYYY-MM-DD HH:MM:SS\n",
    "    tweet_time = datetime.strptime(one_tweet['doc']['data']['created_at'],\n",
    "                                   DATE_FORMAT)\n",
    "    tweet_time = tweet_time.strftime('%Y:%m:%d %H:%M:%S')\n",
    "    try:\n",
    "        location = one_tweet['doc']['includes']['places']\n",
    "    except (KeyError, TypeError):\n",
    "        location = {}\n",
    "    tokens = one_tweet['value']['tokens'].split('|')\n",
    "    tokens = [word.lower() for word in tokens]\n",
    "    simplified_tweet = {\n",
    "        'id': one_tweet['id'],\n",
    "        'tweet_time': tweet_time,\n",
    "        'language_code': one_tweet['doc']['data']['lang'],\n",
    "        'tweet_metrics': one_tweet['doc']['data']['public_metrics'],\n",
    "        'tweet_tags': {'hashtags': one_tweet['value']['tags'].split('|'),\n",
    "                       'tokens': tokens},\n",
    "        'tweet_text': one_tweet['doc']['data']['text'].lower(),\n",
    "        \"sentiment\": one_tweet['doc']['data']['sentiment'],\n",
    "        'location': location\n",
    "    }\n",
    "\n",
    "    return simplified_tweet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [],
   "source": [
    "# English, Mandarin Chinese, Spanish, French, Russian, German, Japanese, Korean, Hindi\n",
    "keyword_R_U = ['russia', 'ukraine', 'putin', 'zelenskyy', 'kyjv', '‰øÑÁΩóÊñØ', '‰πåÂÖãÂÖ∞', 'ÊôÆ‰∫¨', 'Ê≥ΩËøûÊñØÂü∫', 'rusia', 'ucrania', 'russie', 'poutine', 'zelensky', '–†–æ—Å—Å–∏—è', '–£–∫—Ä–∞–∏–Ω–∞', '–ü—É—Ç–∏–Ω', '–ó–µ–ª–µ–Ω—Å–∫–∏–π', 'russland', 'selenskij', '„É≠„Ç∑„Ç¢', '„Ç¶„ÇØ„É©„Ç§„Éä', '„Éó„Éº„ÉÅ„É≥', '„Çº„É¨„É≥„Çπ„Ç≠„Éº', 'Îü¨ÏãúÏïÑ', 'Ïö∞ÌÅ¨ÎùºÏù¥ÎÇò', 'Ìë∏Ìã¥', 'Ï†§Î†åÏä§ÌÇ§', '‡§∞‡•Ç‡§∏', '‡§Ø‡•Ç‡§ï‡•ç‡§∞‡•á‡§®', '‡§™‡•Å‡§§‡§ø‡§®', '‡§ú‡§º‡•á‡§≤‡•á‡§Ç‡§∏‡•ç‡§ï‡•Ä']\n",
    "keyword_war = ['war']\n",
    "keyword_flood = ['flood', 'rainfall']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "todays learning - in this sunburnt country negatively impacted by unsustainable farming practices there are farmers self funding green corridors of native grasses, plants &amp; trees to better manage the flood plains of gomeroi country #caringforcountry #theresabetterway https://t.co/joetz6ok64\n",
      " \n",
      " \n",
      "2\n",
      "@paulretired1951 out of interest drawing on your research knowledge what clay content % would you be aiming for in deep white sands over clay in a 310mm yearly rainfall area?\n",
      " \n",
      " \n",
      "3\n",
      "there is a video from #60minutes going around showing someone on a ukulele. please flood twitter with images of real guitarists. #scottyfromphotoops #auspol https://t.co/uf2w9s2910\n",
      " \n",
      " \n",
      "4\n",
      "funny that a certain someone has been preaching how self sufficient wa is but then along comes some flood water and they have to get food shipped in from sydney. thank god for the federation huh? https://t.co/fbt4dzsbrx\n",
      " \n",
      " \n",
      "5\n",
      "@liddellclaying @paulretired1951 what about for low rainfall areas? 300mm annual\n",
      " \n",
      " \n"
     ]
    }
   ],
   "source": [
    "count = 0\n",
    "with open('twitter-huge.json', 'r') as file:\n",
    "    for index, text in enumerate(file):\n",
    "        if index != 0:\n",
    "            line = json.loads(text[:-2])\n",
    "            if line['doc']['data']['geo'] != {}:\n",
    "                try:\n",
    "                    tweet = extract_tweet_info(line)\n",
    "                    if any(kw in tweet['tweet_tags']['tokens'] for kw in keyword_flood):\n",
    "                        count += 1\n",
    "                        print(count)\n",
    "                        print(tweet['tweet_text'])\n",
    "                        print(\" \")\n",
    "                        print(\" \")\n",
    "                except KeyError:\n",
    "                    pass\n",
    "        if index == 1000000:\n",
    "            break\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5148\n"
     ]
    }
   ],
   "source": [
    "# number of non-english or non-undertermained tweets\n",
    "count = 0\n",
    "with open('twitter-huge.json', 'r') as file:\n",
    "    for index, text in enumerate(file):\n",
    "        if index != 0:\n",
    "            line = json.loads(text[:-2])\n",
    "            if line['doc']['data']['geo'] != {}:\n",
    "                try:\n",
    "                    tweet = extract_tweet_info(line)\n",
    "                    if tweet['language_code'] != 'en' and tweet['language_code'] !=  'und':\n",
    "                        count += 1\n",
    "                except KeyError:\n",
    "                    pass\n",
    "        if index == 1000000:\n",
    "            break\n",
    "print(count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.2"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
